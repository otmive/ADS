{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the vector representations of the images in the dataset\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Load the vector representations\n",
    "df = pd.read_csv('/Users/rz20505/Documents/training_year/applied_data_science/models/yolov5-master/data/vectors.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['feature_vector'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The elements of X are string representations of lists of floats\n",
    "# Convert them to np arrays of floats\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i] = X[i].strip('][').split(', ')\n",
    "    X[i] = [float(x) for x in X[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each of the lists in X to a numpy array\n",
    "X = np.array([np.array(xi) for xi in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_sprite(data):\n",
    "    \"\"\"\n",
    "    Tile images into sprite image. \n",
    "    Add any necessary padding\n",
    "    \"\"\"\n",
    "    \n",
    "    # For B&W or greyscale images\n",
    "    if len(data.shape) == 3:\n",
    "        data = np.tile(data[...,np.newaxis], (1,1,1,3))\n",
    "\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = ((0, n ** 2 - data.shape[0]), (0, 0), (0, 0), (0, 0))\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "            constant_values=0)\n",
    "    \n",
    "    # Tile images into sprite\n",
    "    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3, 4))\n",
    "    # print(data.shape) => (n, image_height, n, image_width, 3)\n",
    "    \n",
    "    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "    # print(data.shape) => (n * image_height, n * image_width, 3) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "\n",
    "LOG_DIR = \"/Users/rz20505/Documents/training_year/applied_data_science/models/yolov5-master/my_testing/tensorboard-logs/\"\n",
    "IMAGES_DIR = \"/Users/rz20505/Documents/training_year/applied_data_science/data/uob_image_set_resized/\"\n",
    "IMAGE_SIZE = (64, 64)\n",
    "SPRITES_FILE = os.path.join(LOG_DIR, \"sprites.png\")\n",
    "\n",
    "# Max sprite size is 8192 x 8192 so this max samples makes visualization easy\n",
    "MAX_NUMBER_SAMPLES = 8191 \n",
    "image_files = glob.glob(os.path.join(IMAGES_DIR, \"*/*.jpg\"))\n",
    "\n",
    "img_data = []\n",
    "for img in image_files[:MAX_NUMBER_SAMPLES]:\n",
    "    input_img = cv2.imread(img)\n",
    "    input_img_resize = cv2.resize(input_img, IMAGE_SIZE) \n",
    "    img_data.append(input_img_resize)\n",
    "img_data = np.array(img_data)\n",
    "\n",
    "sprite = create_sprite(img_data)\n",
    "cv2.imwrite(SPRITES_FILE, sprite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 14:39:07.091086: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-31 14:39:23.653832: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# load the feature vectors, generate metadata, and save them for loading into TensorBoard:\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# define projector\n",
    "from tensorboard.plugins import projector\n",
    "\n",
    "# Create a metadata file\n",
    "with open(os.path.join(LOG_DIR, \"metadata.tsv\"), \"w\") as f:\n",
    "    # f.write(\"Index\\tLabel\\n\")\n",
    "    for index, label in enumerate(df['image'].loc[:MAX_NUMBER_SAMPLES]):\n",
    "        # strip the path of the image /Users/rz20505/Documents/training_year/applied_data_science/data/uob_image_set_resized/11059585/\n",
    "        label = label.split(\"/\")[-1]\n",
    "        # remove the .jpg\n",
    "        label = label.split(\".\")[0]\n",
    "        label = label.split(\"_\")[0]\n",
    "        f.write(\"{}\\n\".format(label))\n",
    "\n",
    "# prepare the embeddings for TensorBoard\n",
    "embedding_var = tf.Variable(X[:MAX_NUMBER_SAMPLES], name=\"embedding\")\n",
    "\n",
    "# save the embedding variable\n",
    "checkpoint = tf.train.Checkpoint(embedding=embedding_var)\n",
    "checkpoint.save(os.path.join(LOG_DIR, \"embedding.ckpt\"))\n",
    "\n",
    "# Create a config file\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
    "embedding.metadata_path = \"metadata.tsv\"\n",
    "embedding.sprite.image_path = \"sprites.png\"\n",
    "embedding.sprite.single_image_dim.extend(IMAGE_SIZE)\n",
    "projector.visualize_embeddings(LOG_DIR, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'embedding:0' shape=(6411, 1500) dtype=float64, numpy=\n",
       "array([[  2.89594746,  -9.57545662,  -7.81872129, ...,  -7.29773617,\n",
       "         -6.42428207,  -4.91425228],\n",
       "       [ -0.41966534, -11.16795731, -10.74712181, ...,  -8.68289948,\n",
       "         -9.22375965,  -8.1003046 ],\n",
       "       [  1.41287422,  -9.68728542,  -8.31381798, ...,  -7.12037849,\n",
       "         -6.57165861,  -5.75563526],\n",
       "       ...,\n",
       "       [ -3.61702681,  -6.38735104,  -6.57878208, ...,  -6.9664216 ,\n",
       "         -6.21995401,  -0.63406545],\n",
       "       [ -2.69703794,  -5.46993256,  -5.3597002 , ...,  -5.80486584,\n",
       "         -5.3774209 ,   1.04141784],\n",
       "       [ -8.7504406 ,  -5.02199125, -10.52400208, ...,  -8.0613575 ,\n",
       "         -7.71609545,   0.90739143]])>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 58091), started 0:00:08 ago. (Use '!kill 58091' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e0f09bd71a9eb499\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e0f09bd71a9eb499\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d09fb8ad6efe61d1c886228c49d873110aaa45536568e2fdba2287d5f51ed66c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
